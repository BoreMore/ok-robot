# To run on hornywombat (laptop), type the following in Terminal:
# mamba activate ok-robot-env
# python path_planning.py debug=False dataset_path=r3d/2024-08-06--experimentroomtake3.r3d cache_path=experimentroom3.pt pointcloud_path=experiment3.ply pointcloud_visualization=True min_height=-1.17

# To run on hornylemur (workstation), type:
# python path_planning.py debug=False dataset_path=r3d/<filename>.r3d cache_path=<filename>.pt pointcloud_path=<filename>.ply pointcloud_visualization=True min_height=<min_height_for_your_map>

# python path_planning.py debug=False dataset_path=r3d/2024-08-08--exproomviconorigin_take2.r3d cache_path=exproomvicon2.pt pointcloud_path=exproomvicon2.ply pointcloud_visualization=True min_height=-1.24

# Change paths and filenames as needed in the above function call.
# Also change min_height to be 0.1 less than the lowest height (z-value) between p1, p2, p3 (as seen on Cloud Compare)

# To visualize map on CloudCompare, run:
# in Terminal: flatpak run org.cloudcompare.CloudCompare
# From within software, open desired map (ply format, auto-generated by path_planning.py the first time it's run with a new r3d map)

import hydra
import math
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import requests
import torch
from omegaconf import OmegaConf
from torch import Tensor


# Set matplotlib backedn to "pdf" to prevent any conflicts with open3d
import matplotlib

#matplotlib.use("pdf")
from matplotlib import pyplot as plt
import open3d as o3d

import sys

sys.path.append("voxel_map")

from a_star.map_util import (
    get_ground_truth_map_from_dataset,
    get_occupancy_map_from_dataset,
)
from a_star.path_planner import PathPlanner
from a_star.data_util import get_posed_rgbd_dataset
from voxel_map_localizer import VoxelMapLocalizer
from a_star.visualizations import visualize_path

import math
import os

import sys
import pickle

sys.path.append("voxel_map")

from dataloaders import (
    R3DSemanticDataset,
    OWLViTLabelledDataset,
)

from skspatial.objects import Vector
from skspatial.plotting import plot_2d
from skspatial.objects import Point


from mpl_toolkits.mplot3d import Axes3D

import transformation_helper as th
from numpy.linalg import inv


def load_dataset(cfg):
    if os.path.exists(cfg.cache_path):
        if (
            input(
                "\nWe have found an existing semantic memory, do you want to use it? [y|n]"
            ).lower()
            == "y"
        ):
            print("\n\nSemantic memory ready!\n\n")
            return torch.load(cfg.cache_path)
    print(
        "\n\nFetching semantic memory from record3D file, might take some time ....\n\n"
    )
    r3d_dataset = R3DSemanticDataset(
        cfg.dataset_path, cfg.custom_labels, subsample_freq=cfg.sample_freq
    )
    semantic_memory = OWLViTLabelledDataset(
        r3d_dataset,
        owl_model_name=cfg.web_models.owl,
        sam_model_type=cfg.web_models.sam,
        device=cfg.memory_load_device,
        threshold=cfg.threshold,
        subsample_prob=cfg.subsample_prob,
        visualize_results=cfg.visualize_results,
        visualization_path=cfg.visualization_path,
    )
    torch.save(semantic_memory, cfg.cache_path)
    print("\n\nSemantic memory ready!\n\n")
    return semantic_memory

@hydra.main(version_base="1.2", config_path="configs", config_name="path.yaml")
def main(cfg):
    cfg = OmegaConf.structured(OmegaConf.to_yaml(cfg))
    semantic_memory = load_dataset(cfg)
    conservative = cfg.map_type == "conservative_vlmap"
    # ceil height is set to floor height+1.5, as objects higher than that will not obstruct robots anymore 
    cfg.max_height = cfg.min_height + 1.5
    planner = PathPlanner(
        cfg.dataset_path,
        cfg.min_height,
        cfg.max_height,
        cfg.resolution,
        cfg.occ_avoid_radius,
        conservative,
    )
    localizer = VoxelMapLocalizer(
        semantic_memory,
        owl_vit_config=cfg.web_models.owl,
        device=cfg.path_planning_device,
    )

    obstacle_map = planner.occupancy_map
    minx, miny = obstacle_map.origin
    (ycells, xcells), resolution = obstacle_map.grid.shape, obstacle_map.resolution
    maxx, maxy = minx + xcells * resolution, miny + ycells * resolution
    dataset = planner.dataset
    ground_truth_map = get_ground_truth_map_from_dataset(
        dataset, cfg.resolution, (cfg.min_height, cfg.max_height)
    )

    while True:
        if cfg.debug:
            A = input("A: ") # will need these inputs from language inputs 
            B = input("B: ")
            # get start_xy from robot (get current position and orientation somehow, assume robot is on tapes)
            end_xyz = localizer.localize_AonB(A, B)
            end_xy = end_xyz[:2]
            try:
                paths = planner.plan(
                    start_xy=(0.869957, 1.796761), end_xy=end_xy, remove_line_of_sight_points=True
                )
            except:
                # Sometimes, start_xy might be an occupied obstacle point, in this case, A* is going to throw an error
                # In this case, we will throw an error and still visualize
                print(
                    'A* planner said that your robot stands on an occupied point,\n\
                    it might be either your hector slam is not tracking robot current position,\n\
                    or your min_height or max_height is set to incorrect value so obstacle map is not accurate!'
                )
                paths = None
            print(paths)
            if cfg.pointcloud_visualization:
                visualize_path(paths, end_xyz, cfg) # visualize_path(None, end_xyz, cfg)

        else:
            start_xy = (0.869957, 1.796761) # corresponds to point (x, y) of point p1 in code below
            # LATER, NEED TO GET: A and B, EXTRACTED FROM USER INPUT VIA LLM. FOR NOW, INPUT MANUALLY HERE
            A = 'soccer ball'
            B = 'floor'

            end_xyz = localizer.localize_AonB(A, B)
            end_xy = end_xyz[:2]
            try:
                paths = planner.plan(
                    start_xy=start_xy[:2], end_xy=end_xy, remove_line_of_sight_points=True
                )
            except:
                # Sometimes, start_xy might be an occupied obstacle point, in this case, A* is going to throw an error
                # In this case, we will throw an error and still visualize
                print(
                    'A* planner said that your robot stands on an occupied point,\n\
                    it might be either your hector slam is not tracking robot current position,\n\
                    or your min_height or max_height is set to incorrect value so obstacle map is not accurate!'
                )
                paths = None
            if cfg.pointcloud_visualization:
                visualize_path(paths, end_xyz, cfg)
            end_pt = planner.a_star_planner.to_pt(paths[-1][:2])
            theta = paths[-1][2] if paths[-1][2] > 0 else paths[-1][2] + 2 * np.pi

        # Plotting
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))

        # Draw paths only when path planning is done successfully
        if not cfg.debug and paths:
            xs, ys, thetas = zip(*paths)

        # Draw on obstacle map used for path planning
        axes[0].imshow(obstacle_map.grid[::-1], extent=(minx, maxx, miny, maxy))
        if not cfg.debug and paths:
            axes[0].plot(xs, ys, c="r")
            axes[0].scatter(start_xy[0], start_xy[1], s=50, c="white")
            axes[0].scatter(xs, ys, c="cyan", s=10)
            axes[0].scatter(end_xyz[0], end_xyz[1], s=50, c="g")
        elif not cfg.debug:
            # This means that we have start_xy and tried path planning, yet path planning failed.
            # For debugging purpose, we will draw start_xy and end_xyt
            axes[0].scatter(start_xy[0], start_xy[1], s=50, c="white")
            axes[0].scatter(end_xyz[0], end_xyz[1], s=50, c="g")
        else:
            axes[0].scatter(end_xyz[0], end_xyz[1], s=50, c="g")

        # Draw on ground truth obstacle map
        axes[1].imshow(ground_truth_map.grid[::-1], extent=(minx, maxx, miny, maxy))
        if not cfg.debug and paths:
            axes[1].plot(xs, ys, c="r")
            axes[1].scatter(start_xy[0], start_xy[1], s=50, c="white")
            axes[1].scatter(xs, ys, c="cyan", s=10)
            axes[1].scatter(end_xyz[0], end_xyz[1], s=50, c="g")
        elif not cfg.debug:
            axes[0].scatter(start_xy[0], start_xy[1], s=50, c="white")
            axes[0].scatter(end_xyz[0], end_xyz[1], s=50, c="g")
        else:
            axes[0].scatter(end_xyz[0], end_xyz[1], s=50, c="g")

        if not os.path.exists(cfg.save_file + "/" + A):
            os.makedirs(cfg.save_file + "/" + A)
        print(cfg.save_file + "/" + A + "/navigation_vis.jpg")
        fig.savefig(cfg.save_file + "/" + A + "/navigation_vis.jpg")

        # HARDCODED POINTS -- THESE ARE IN MAPPED AREA VISIBLE TO VICON. COORDINATES ARE FOUND USING CLOUDCOMPARE SOFTWARE.
        p1 = Point([0.869957, 1.796761, -1.248048])
        p2 = Point([0.536515, 1.466343, -1.252263])
        p3 = Point([1.198159, 1.499441, -1.251200])
        # p1 to p2: +x direction
        # p3 corresponds to another marker on the floor
        # p1p2 cross p2p3 is used to get +z direction
        # then p2p3 cross z is used to get +y direction
        # code is in transformation_helper.py

        transformed_paths = []

        tf = th.get_transform_matrix(p1, p2, p3)
        tf_inv = inv(tf)

        for path in paths:
            x, y, theta = path
            v = np.array([x, y, 0, 1])
            v_transformed = tf_inv @ v

            transformed_paths.append(v_transformed[:2].tolist())

        transformed_paths = np.array(transformed_paths)
        plt.plot(transformed_paths)
        plt.show()
        print(tf)
  
        transformed_end_xyz = tf_inv @ np.array([end_xyz[0], end_xyz[1], end_xyz[2], 1])

        print(transformed_paths)
        print(transformed_end_xyz)

        with open("print_paths.txt", "w") as f:
            f.write(str(transformed_paths) + "\n" + str(transformed_end_xyz))
        

        with open('/home/hornylemur/ament_ws/src/ok-robot/ok_robot_navigation/ok_robot_navigation/path_result_transformed_fixedsoccer.pkl', 'wb') as f:
            pickle.dump([transformed_paths, transformed_end_xyz], f)

        return paths, end_xyz


if __name__ == "__main__":
    main()
